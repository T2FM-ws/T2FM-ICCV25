<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Invited Speakers - T2FM Workshop @ ICCV 2025</title>
<meta content="T2FM Workshop - Invited Speakers" name="description"/>
<link href="favicon.svg" rel="icon"/>
<!-- Bulma CSS for layout -->
<link href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" rel="stylesheet"/>
<!-- Font Awesome for icons -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" rel="stylesheet"/>
<!-- Custom CSS -->
<style>
    body { background-color: #f8f8f8; }
    .hero {
      position: relative;
      background: url('data/teaser.png') center/cover no-repeat;
      color: #222;
      padding: 5rem 1.5rem;
      background-attachment: fixed;
    }
    .hero::before {
        content: "";
        position: absolute;
        top: 0; left: 0;
        width: 100%; height: 100%;
        background: rgba(255, 255, 255, 0.4); 
        z-index: 0;
      }
      
      .hero > .container {
        position: relative;
        z-index: 1;
      }
    .button-nav a {
      margin: 0 0.5rem;
      background: rgba(255,255,255,0.8);
      border-radius: 8px;
    }
    .section-title {
      color: #4a4a4a;
      margin-bottom: 1rem;
    }
    .card-content p {
      margin-bottom: 0.25rem;
    }
    .footer {
      background-color: #fafafa;
      padding: 2rem 1.5rem;
      font-size: 0.9rem;
    }
  </style>
</head>
<body>
<!-- Header -->
<section class="hero is-medium is-bold">
<div class="container has-text-centered">
<h1 class="title is-1">üîí Trustworthy FMs Workshop</h1>
<h2 class="subtitle is-3">Trust Before Use: Building Foundation Models that You Can Trust</h2>
<p class="subtitle is-5">
        üìç In conjunction with <strong>ICCV 2025</strong> ‚Äî Oct. 19‚Äì23, Honolulu, Hawai'i
      </p>
      <a class="button is-primary" href="index.html">Overview</a>
      <a class="button is-primary" href="cfp.html">Call for Papers</a>
      <a class="button is-primary" href="speakers.html">Invited Speakers</a>
      <a class="button is-primary" href="organizers.html">Senior Organizers</a>
      <a class="button is-primary" href="pcmember.html">Organizers</a>
      <a class="button is-primary" href="attending.html">Attending</a>
</div>
</div>
</section>

<!-- Schedule -->
<section class="section" id="schedule">
  <div class="container">
    <h2 class="title section-title">üóì Schedule</h2>
    <p class="mb-4">
      <strong>ICCV 2025 Workshop Day 10/20</strong> ‚Ä¢ Honolulu, Hawai'i ‚Ä¢ <em>Afternoon Session</em>
    </p>

    <!-- Desktop view -->
    <div class="table-container is-hidden-touch">
      <table class="table is-fullwidth is-striped is-hoverable">
        <thead>
          <tr>
            <th style="width: 120px;">Time</th>
            <th>Session</th>
            <th style="width: 280px;">Speakers / Notes</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>1:00 - 1:10</td><td>Opening Remarks</td><td>Workshop Start</td></tr>
          <tr><td>1:10 - 1:40</td><td>Session S1</td><td>Shaoron Li</td></tr>
          <tr><td>1:40 - 2:10</td><td>Session S2</td><td>Salman Avestimehr</td></tr>
          <tr><td>2:10 - 2:20</td><td>Oral Presentations I</td><td>Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</td></tr>
          <tr><td>2:20 - 2:30</td><td>Oral Presentations II</td><td>DASH: Detection and Assessment of Systematic Hallucinations of VLMs</td></tr>
          <tr><td>2:30 - 2:40</td><td>Oral Presentations III</td><td>GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation</td></tr>
          <tr><td>2:30 - 3:10</td><td>Session S3</td><td>Yao Qin</td></tr>
          <tr><td>3:00 - 4:00</td><td>Poster Session</td><td>Interactive discussion</td></tr>
          <tr><td>4:00 - 4:30</td><td>Session S4</td><td>Chengzhi Mao</td></tr>
          <tr><td>4:30 - 5:00</td><td>Session S5</td><td>Mazda Moayeri</td></tr>
          <tr><td>5:10 - 5:20</td><td>Oral Presentations IV</td><td>Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models</td></tr>
          <tr><td>5:20 - 5:30</td><td>Oral Presentations V</td><td>Doxing via the Lens: Revealing Location-related Privacy Leakage on Multi-modal Large Reasoning Model</td></tr>
          <tr><td>5:30 - 5:40</td><td>Oral Presentations VI</td><td>Harnessing the Computation Redundancy in ViTs to Boost Adversarial Transferability</td></tr>
          <tr><td>5:40 - 5:50</td><td>Closing</td><td>Wrap-up &amp; announcements</td></tr>
        </tbody>
      </table>
    </div>

<!-- Footer -->
<footer class="footer">
<div class="content has-text-centered">
<p>
         Contact: <a href="mailto:t2fm_workshop@googlegroups.com">t2fm_workshop@googlegroups.com</a><br/> or <a href="mailto:hust0426@gmail.com">hust0426@gmail.com</a><br/>
        Website template adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a><br/>
        Licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
</p>
</div>
</footer>
</body>
</html>
