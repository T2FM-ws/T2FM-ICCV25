<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Accepeted papers - T2FM Workshop @ ICCV 2025</title>
<meta content="T2FM Workshop - Accepeted papers" name="description"/>
<link href="favicon.svg" rel="icon"/>
<!-- Bulma CSS for layout -->
<link href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" rel="stylesheet"/>
<!-- Font Awesome for icons -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" rel="stylesheet"/>
<!-- Custom CSS -->
<style>
    body { background-color: #f8f8f8; }
    .hero {
      position: relative;
      background: url('data/teaser.png') center/cover no-repeat;
      color: #222;
      padding: 5rem 1.5rem;
      background-attachment: fixed;
    }
    .hero::before {
        content: "";
        position: absolute;
        top: 0; left: 0;
        width: 100%; height: 100%;
        background: rgba(255, 255, 255, 0.4); 
        z-index: 0;
      }
      
      .hero > .container {
        position: relative;
        z-index: 1;
      }
    .button-nav a {
      margin: 0 0.5rem;
      background: rgba(255,255,255,0.8);
      border-radius: 8px;
    }
    .section-title {
      color: #4a4a4a;
      margin-bottom: 1rem;
    }
    .card-content p {
      margin-bottom: 0.25rem;
    }
    .footer {
      background-color: #fafafa;
      padding: 2rem 1.5rem;
      font-size: 0.9rem;
    }
  </style>
</head>
<body>
<!-- Header -->
<section class="hero is-medium is-bold">
<div class="container has-text-centered">
<h1 class="title is-1">üîí Trustworthy FMs Workshop</h1>
<h2 class="subtitle is-3">Trust Before Use: Building Foundation Models that You Can Trust</h2>
<p class="subtitle is-5">
        üìç In conjunction with <strong>ICCV 2025</strong> ‚Äî Oct. 19‚Äì23, Honolulu, Hawai'i
      </p>
      <a class="button is-primary" href="index.html">Overview</a>
<a class="button is-primary" href="schedule.html">Schedule</a>
<a class="button is-primary" href="accepeted_papers.html">Accepeted Papers</a>
<a class="button is-primary" href="cfp.html">Call for Papers</a>
<a class="button is-primary" href="speakers.html">Invited Speakers</a>
<a class="button is-primary" href="organizers.html">Senior Organizers</a>
<a class="button is-primary" href="pcmember.html">Organizers</a>
<a class="button is-primary" href="attending.html">Attending</a>
</div>
</div>
</section>


<!-- Accepted Papers -->
<section class="section" id="accepted-papers">
  <div class="container">
    <h2 class="title section-title">üìë Accepted Papers</h2>
    <p>
      We are excited to announce the accepted papers for the T2FM Workshop at ICCV 2025.  
      All papers will be presented during oral or poster sessions at the workshop.  
      The list will be updated continuously as authors confirm participation.
    </p>

    <!-- Example list of accepted papers -->
    <div class="content mt-4">
      <ul>
        <li>
          <strong>VisualDAN: Exposing Vulnerabilities in VLMs with Visual-Driven DAN Commands</strong><br/>
          <em>Aofan Liu, Lulu Tang</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</strong><br/>
          <em>Md Yousuf Harun, Jhair Gallardo, Christopher Kanan</em><br/>
          <span class="tag is-success is-light">Oral</span>
        </li>
        <li>
          <strong>What Variables Affect Out-of-Distribution Generalization in Pretrained Models?</strong><br/>
          <em>Md Yousuf Harun, Kyungbok Lee, Jhair Gallardo, Giri P Krishnan, Christopher Kanan</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Federated Foundation Models Raise New Concerns of Robustness, Privacy, and Fairness</strong><br/>
          <em>Jiaqi Wang, Xi Li</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>DASH: Detection and Assessment of Systematic Hallucinations of VLMs</strong><br/>
          <em>Maximilian Augustin, Yannic Neuhaus, Matthias Hein</em><br/>
          <span class="tag is-info is-light">Oral</span>
        </li>
        <li>
          <strong>GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation</strong><br/>
          <em>Sohyun Lee, Yeho Gwon, Lukas Hoyer, Suha Kwak</em><br/>
          <span class="tag is-info is-light">Oral</span>
        </li>
        <li>
          <strong>FairReason: Balancing Reasoning and Social Bias in MLLMs</strong><br/>
          <em>Zhenyu Pan, Yutong Zhang, Jianshu Zhang, Haoran Lu, Haozheng Luo, Yuwei Han, Philip S. Yu, Manling Li, Han Liu</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense</strong><br/>
          <em>Shuyang Hao, Yiwei Wang, Bryan Hooi, Ming-Hsuan Yang, Jun Liu, Chengcheng Tang, Zi Huang, Yujun Cai</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Rethinking the Safety Landscape for Foundation Models: A Multi-Modal Perspective</strong><br/>
          <em>Xi Li, Shu Zhao, Fei Zhao, Runlong Yu</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Ditect: Lightweight Harmful Content Detector for Text-to-Image Generation</strong><br/>
          <em>Hangfan Zhang, Bochuan Cao, Jinghui Chen, Lu Lin, Jinyuan Jia, Dinghao Wu</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>FilterRAG: Zero-Shot Informed Retrieval-Augmented Generation to Mitigate Hallucinations in VQA</strong><br/>
          <em>S M Sarwar</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>A Dual-Protection Framework for Copyright Protection and Image Editing Using Multi-Label Conformal Prediction</strong><br/>
          <em>Yuxuan Sun, Sowmen Das, Zhuo Zhi, Minghe Shen, Ziquan Liu, Miguel R. D. Rodrigues</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>The Hidden Vulnerabilities of AI-Generated Code: A Cross-Language Security Investigation</strong><br/>
          <em>Jinghao Wang, Carter Yagemann</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Understanding Alignment in Multimodal LLMs: A Comprehensive Study</strong><br/>
          <em>Elmira Amirloo, Jean-Philippe Fauconnier, Christoph Roesmann, Christian Kerl, Rinu Boney, Yusu Qian, Zirui Wang, Afshin Dehghan, Yinfei Yang, Zhe Gan, Peter Grasch</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models</strong><br/>
          <em>Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Shahbaz Khan, Salman Khan</em><br/>
          <span class="tag is-info is-light">Oral</span>
        </li>
        <li>
          <strong>Safety Mirage: How Spurious Correlations Undermine MLLM Safety Fine-tuning</strong><br/>
          <em>Yiwei Chen, Yuguang Yao, Yihua Zhang, Bingquan Shen, Gaowen Liu, Sijia Liu</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>JensUn: Effective LLM Unlearning via the Jensen-Shannon Divergence</strong><br/>
          <em>Naman Deep Singh, Maximilian M√ºller, Francesco Croce, Matthias Hein</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety</strong><br/>
          <em>Zhenyu Pan, Yiting Zhang, Yutong Zhang, Yuwei Han, Jianshu Zhang, Haozheng Luo, Dennis Wu, Hong-Yu Chen, Manling Li, Philip S. Yu, Han Liu</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Differentially Private Adaptation of Diffusion Models via Noisy Aggregated Embeddings</strong><br/>
          <em>Pura Peetathawatchai, Wei-Ning Chen, Berivan Isik, Sanmi Koyejo, Albert No</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Synthetic Text-to-Image Pre-training through Fractals with Pseudo-Captions</strong><br/>
          <em>Jumpei Nakao, Yuto Shibata, Rintaro Yanagi, Masaru Isonuma, Hirokatsu Kataoka, Junichiro Mori, Ichiro Sakata</em><br/>
          <span class="tag is-info is-light">Poster</span>
        </li>
        <li>
          <strong>Doxing via the Lens: Revealing Location-related Privacy Leakage on Multi-modal Large Reasoning Model</strong><br/>
          <em>Weidi Luo, Tianyu Lu, Qiming Zhang, Xiaogeng Liu, Bin Hu, Yue Zhao, Jieyu Zhao, Song Gao, Patrick McDaniel, Zhen Xiang, Chaowei Xiao</em><br/>
          <span class="tag is-info is-light">Oral</span>
        </li>
      </ul>
    </div>

  </div>
</section>



<!-- Footer -->
<footer class="footer">
<div class="content has-text-centered">
<p>
         Contact: <a href="mailto:t2fm_workshop@googlegroups.com">t2fm_workshop@googlegroups.com</a><br/> or <a href="mailto:hust0426@gmail.com">hust0426@gmail.com</a><br/>
        Website template adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a><br/>
        Licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
</p>
</div>
</footer>
</body>
</html>
